{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a0c8d25",
   "metadata": {},
   "source": [
    "# 0. Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edd754d",
   "metadata": {},
   "source": [
    "## 0.1. Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0fa985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv\n",
    "# !pip install python-binance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776dd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c3096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get(\"API_KEY\") if os.environ.get(\"API_KEY\") else \"\"\n",
    "api_secret = os.environ.get(\"API_SECRET\") if os.environ.get(\"API_SECRET\") else \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877efb33",
   "metadata": {},
   "source": [
    "## 0.2. Connecting API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60663edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://api.binance.com\"\n",
    "api_call = \"/api/v3/ticker/price\"\n",
    "headers = {\"content-type\": \"application/json\", \"X-MBX-APIKEY\": api_key}\n",
    "\n",
    "response = requests.get(url + api_call, headers=headers)\n",
    "response = json.loads(response.text)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe786c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(response)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ff6833",
   "metadata": {},
   "source": [
    "# 1. Binance API\n",
    "\n",
    "```text\n",
    "Documentation: https://developers.binance.com/docs/binance-spot-api-docs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d341aa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinanceAPI:\n",
    "    def __init__(self, api_key=None, api_secret=None):\n",
    "        self.base_url = \"https://api.binance.com\"\n",
    "        self.api_key = api_key\n",
    "        self.api_secret = api_secret\n",
    "        \n",
    "    # ข้อมูลเทียนหรือกราฟแท่งเทียนในอดีตสำหรับคู่การเทรดที่กำหนดตาม Symbol\n",
    "    def get_klines(self, symbol, interval, limit=1000, start_time=None, end_time=None):\n",
    "        endpoint = \"/api/v3/klines\"\n",
    "        params = {\n",
    "            'symbol': symbol,\n",
    "            'interval': interval,\n",
    "            'limit': limit\n",
    "        }\n",
    "        \n",
    "        if start_time:\n",
    "            params['startTime'] = start_time\n",
    "        if end_time:\n",
    "            params['endTime'] = end_time\n",
    "            \n",
    "        response = requests.get(self.base_url + endpoint, params=params)\n",
    "        return response.json()\n",
    "    \n",
    "    def get_n_symbol(self, n) :\n",
    "        endpoint = \"/api/v3/ticker/price\"\n",
    "        headers = {\"content-type\": \"application/json\", \"X-MBX-APIKEY\": self.api_key}\n",
    "        response = requests.get(self.base_url + endpoint, headers=headers)\n",
    "        response = json.loads(response.text)\n",
    "        df = pd.DataFrame.from_records(response)\n",
    "        return df.loc[:n, \"symbol\"] \n",
    "    \n",
    "    def get_server_time(self, as_timestamp=False) :\n",
    "        endpoint = \"/api/v3/time\"\n",
    "        response = requests.get(self.base_url + endpoint)\n",
    "        ts = response.json()[\"serverTime\"]\n",
    "        if as_timestamp:\n",
    "            return ts\n",
    "        time = datetime.fromtimestamp(ts / 1000)\n",
    "        return time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # สถิติการเปลี่ยนแปลงราคา 24 ชั่วโมงสำหรับคู่การเทรดที่กำหนดตาม Symbol\n",
    "    def get_24hr_ticker(self, symbol):\n",
    "        endpoint = \"/api/v3/ticker/24hr\"\n",
    "        params = {'symbol': symbol}\n",
    "        response = requests.get(self.base_url + endpoint, params=params)\n",
    "        return response.json()\n",
    "    \n",
    "    # ข้อมูล order book ปัจจุบันสำหรับคู่การเทรดที่กำหนดตาม Symbol\n",
    "    def get_orderbook(self, symbol, limit=100):\n",
    "        endpoint = \"/api/v3/depth\"\n",
    "        params = {'symbol': symbol, 'limit': limit}\n",
    "        response = requests.get(self.base_url + endpoint, params=params)\n",
    "        return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5598b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = BinanceAPI(api_key, api_secret)\n",
    "api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256f7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.get_server_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9584b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.get_n_symbol(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac46b6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.get_klines(\"ETHBTC\", \"1m\", limit=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12af73b",
   "metadata": {},
   "source": [
    "# 2. Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b7aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_historical_data(api: BinanceAPI, symbol, interval='1m', days=1, end_time=None):\n",
    "    if end_time is None:\n",
    "        end_time = int(api.get_server_time(as_timestamp=True))\n",
    "    start_time = end_time - (days * 24 * 60 * 60 * 1000)\n",
    "    \n",
    "    klines = api.get_klines(\n",
    "        symbol=symbol,\n",
    "        interval=interval,\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "    )\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(klines, columns=[\n",
    "        'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "        'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "        'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n",
    "    ])\n",
    "    \n",
    "    # Convert data types\n",
    "    numeric_columns = ['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume']\n",
    "    for col in numeric_columns:\n",
    "        df[col] = pd.to_numeric(df[col])\n",
    "    \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')\n",
    "    df.drop([\"ignore\"], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa310ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = BinanceAPI(api_key, api_secret)\n",
    "symbol = \"BNBBTC\"\n",
    "\n",
    "train_df = collect_historical_data(api, symbol, interval=\"5m\", days=4)\n",
    "\n",
    "test_df = collect_historical_data(api, symbol, interval=\"5m\", days=1, end_time=None)\n",
    "test_df = test_df[test_df['timestamp'] > train_df['timestamp'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb14bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa575d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bedcb98",
   "metadata": {},
   "source": [
    "<b>Columns</b>\n",
    "\n",
    "1) <b>open</b>: ราคา *แรกสุด* ที่มีการซื้อขายในช่วงเวลา t\n",
    "2) <b>high</b>: ราคา *สูงสุด* ที่มีการซื้อขายในช่วงเวลา t\n",
    "3) <b>low</b>: ราคา *ต่ำสุด* ที่มีการซื้อขายในช่วงเวลา t\n",
    "4) <b>close</b>: ราคา *สุดท้าย* ที่มีการซื้อขายในช่วงเวลา t\n",
    "\n",
    "``` \n",
    "4 Columns นี้มีการพิจารณาค่าตัวเลขเหมือนกัน เข่น 0.2389 คือ 1 ETH แลกได้ 0.2389 BTC \n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "5. <b>volume</b>: จำนวนเหรียญหลักรวมที่มีการซื้อขายในช่วงเวลา t\n",
    "6. <b>quote_asset_volume</b>: จำนวนเหรียญคู่รวมที่มีการซื้อขายในช่วงเวลา t BTC รวม\n",
    "7. <b>number_of_trades</b>: จำนวนครั้งที่มีการซื้อขายในช่วงเวลา t\n",
    "8. <b>taker_buy_base_asset_volume</b>: จำนวนเหรียญหลักรวมที่มีการรีบซื้อในทันทีในช่วงเวลา t\n",
    "9. <b>taker_buy_quote_asset_volume</b>: จำนวนเหรียญคู่รวมที่มีการรีบซื้อในทันทีในช่วงเวลา t\n",
    "\n",
    "---\n",
    "\n",
    "10. <b>timestamp</b>: เวลาเริ่มต้นของการซื้อขาย\n",
    "11. <b>close_time</b>: เวลาสิ้นสุดของการซื้อขาย\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4993b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01450077",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"taker_buy_base_asset_volume\"] = train_df[\"taker_buy_base_asset_volume\"].astype(float)\n",
    "train_df[\"taker_buy_quote_asset_volume\"] = train_df[\"taker_buy_quote_asset_volume\"].astype(float)\n",
    "\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6fdd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d2a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"taker_buy_base_asset_volume\"] = test_df[\"taker_buy_base_asset_volume\"].astype(float)\n",
    "test_df[\"taker_buy_quote_asset_volume\"] = test_df[\"taker_buy_quote_asset_volume\"].astype(float)\n",
    "\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f044f9",
   "metadata": {},
   "source": [
    "# 3. Create Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8458984f",
   "metadata": {},
   "source": [
    "## 3.1. Moving Average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e1979",
   "metadata": {},
   "source": [
    "คำนวณค่าเฉลี่ยแบบเคลื่อนที่ทุกๆ n จุด แล้วดูแนวโน้มค่าเฉลี่ยเหล่านั้น"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dad8ce",
   "metadata": {},
   "source": [
    "- Bullish: มีแนวโน้มว่าในอนาคต ราคาสูงขึ้น -> 1 ETH มีแนวโน้มจะได้ BTC มากขึ้น\n",
    "    - ถ้าเรามี ETH อยู่ เราควรถือไว้ หรือซื้อ ETH เพิ่มเติม\n",
    "    - ถ้าเรามี BTC อยู่ เราควรขายเพื่อซื้อ ETH\n",
    "     \n",
    "- Bearish: มีแนวโน้มว่าในอนาคต ราคาลดลง -> 1 ETH มีแนวโน้มจะได้ BTC น้อยลง\n",
    "    - ถ้าเรามี ETH อยู่ เราควรขายเพื่อซื้อ BTC\n",
    "    - ถ้าเรามี BTC อยู่ เราควรถือไว้ หรือซื้อ BTC เพิ่มเติม"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336c6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_moving_average(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    \n",
    "    price_col = \"close\"\n",
    "    \n",
    "    # SMA\n",
    "    for period in [20, 50, 200]:\n",
    "        df[f'SMA_{period}'] = df[price_col].rolling(period, min_periods=1).mean()\n",
    "    \n",
    "    # EMA   \n",
    "    for period in [12, 26]:\n",
    "        df[f'EMA_{period}'] = df[price_col].ewm(span=period, adjust=False).mean()\n",
    "    \n",
    "    # Golden Cross: 50-day SMA crosses above 200-day SMA (Long-term Bullish)\n",
    "    df['golden_cross'] = ((df['SMA_50'] > df['SMA_200']) & \n",
    "                         (df['SMA_50'].shift(1) <= df['SMA_200'].shift(1))).astype(int)\n",
    "    \n",
    "    # Death Cross: 50-day SMA crosses below 200-day SMA (Long-term Bearish)\n",
    "    df['death_cross'] = ((df['SMA_50'] < df['SMA_200']) & \n",
    "                        (df['SMA_50'].shift(1) >= df['SMA_200'].shift(1))).astype(int)\n",
    "    \n",
    "    # Bullish Cross: 20-day SMA crosses above 50-day SMA (Short-term Bullish)\n",
    "    df['bullish_cross'] = ((df['SMA_20'] > df['SMA_50']) & \n",
    "                          (df['SMA_20'].shift(1) <= df['SMA_50'].shift(1))).astype(int)\n",
    "    \n",
    "    # Bearish Cross: 20-day SMA crosses below 50-day SMA (Short-term Bearish)\n",
    "    df['bearish_cross'] = ((df['SMA_20'] < df['SMA_50']) & \n",
    "                          (df['SMA_20'].shift(1) >= df['SMA_50'].shift(1))).astype(int)\n",
    "    \n",
    "    # EMA Bullish Cross: 12-day EMA crosses above 26-day EMA (Momentum turning up)\n",
    "    df['ema_bullish_cross'] = ((df['EMA_12'] > df['EMA_26']) & \n",
    "                              (df['EMA_12'].shift(1) <= df['EMA_26'].shift(1))).astype(int)\n",
    "    \n",
    "    # EMA Bearish Cross: 12-day EMA crosses below 26-day EMA (Momentum turning down)\n",
    "    df['ema_bearish_cross'] = ((df['EMA_12'] < df['EMA_26']) & \n",
    "                              (df['EMA_12'].shift(1) >= df['EMA_26'].shift(1))).astype(int)\n",
    "    \n",
    "    # 0 = Very Bearish, 5 = Very Bullish\n",
    "    df['trend_strength'] = ((df[price_col] > df['SMA_20']).astype(int) + \n",
    "                           (df[price_col] > df['SMA_50']).astype(int) + \n",
    "                           (df[price_col] > df['SMA_200']).astype(int) +\n",
    "                           (df[price_col] > df['EMA_12']).astype(int) +\n",
    "                           (df[price_col] > df['EMA_26']).astype(int))\n",
    "    \n",
    "    # Price Distance from MAs\n",
    "    # Positive = Above MA \n",
    "    # Negative = Below MA\n",
    "    df['price_sma20_dist'] = ((df[price_col] - df['SMA_20']) / df['SMA_20']).fillna(0)\n",
    "    df['price_sma50_dist'] = ((df[price_col] - df['SMA_50']) / df['SMA_50']).fillna(0)\n",
    "    df['price_sma200_dist'] = ((df[price_col] - df['SMA_200']) / df['SMA_200']).fillna(0)\n",
    "    \n",
    "    # Price Distance from EMAs\n",
    "    # Positive = Above MA \n",
    "    # Negative = Below MA\n",
    "    df['price_ema12_dist'] = ((df[price_col] - df['EMA_12']) / df['EMA_12']).fillna(0)\n",
    "    df['price_ema26_dist'] = ((df[price_col] - df['EMA_26']) / df['EMA_26']).fillna(0)\n",
    "    \n",
    "    # Bullish Alignment: SMA_20 > SMA_50 > SMA_200\n",
    "    df['bullish_alignment'] = ((df['SMA_20'] > df['SMA_50']) & \n",
    "                              (df['SMA_50'] > df['SMA_200'])).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb21f21",
   "metadata": {},
   "source": [
    "## 3.2. Relative Strength Index (RSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8790ef08",
   "metadata": {},
   "source": [
    "https://www.investopedia.com/terms/r/rsi.asp\n",
    "- บ่งบอกความแรงของราคา (Momentum) ในช่วงเวลาที่กำหนด ซึ่งมักนิยมใช้ 14 วัน\n",
    "- มีค่าอยู่ในช่วงระหว่าง 0 ถึง 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc37c0d",
   "metadata": {},
   "source": [
    "พิจารณา ETHBTC\n",
    "- RSI สูง (>70) = คนซื้อ ETH ด้วย BTC เยอะมาก \n",
    "    - ETH อาจแพงเกินไปที่จะซื้อตอนนี้ \n",
    "    - ตอนนี้เราควรขาย ETH และซื้อ BTC\n",
    "- RSI ต่ำ (<30) = คนขาย ETH เพื่อซื้อ BTC เยอะมาก \n",
    "    - ETH อาจถูกเกินไปที่จะขายตอนนี้ \n",
    "    - ตอนนี้เราควรซื้อ ETH และขาย BTC\n",
    "- RSI กลางๆ (~50) = การซื้อขาย ETH/BTC ปกติดี  \n",
    "    - ตอนนี้ควรรอดูสถานการณ์ก่อน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b1cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rsi(df:pd.DataFrame, period=14):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    price_col='close'\n",
    "    \n",
    "    delta = df[price_col].diff()\n",
    "    \n",
    "    gains = delta.where(delta > 0, 0)\n",
    "    losses = -delta.where(delta < 0, 0)\n",
    "    \n",
    "    # Average Gain and Loss with Exponential Moving Average\n",
    "    avg_gains = gains.ewm(alpha=1/period, adjust=False).mean()\n",
    "    avg_losses = losses.ewm(alpha=1/period, adjust=False).mean()\n",
    "    \n",
    "    # Calculate RSI\n",
    "    rs = avg_gains / avg_losses\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "\n",
    "    df['rsi'] = rsi\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b48b7d",
   "metadata": {},
   "source": [
    "## 3.3. MACD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93bffa",
   "metadata": {},
   "source": [
    "- ใช้ดูแนวโน้ม (trend) และโมเมนตัม (momentum) ของราคา \n",
    "- ดูจากความแตกต่างของค่าเฉลี่ยเคลื่อนที่แบบ EMA สองเส้น (fast: EMA12 ลบกับ slow: EMA26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a5c724",
   "metadata": {},
   "source": [
    "พิจารณา ETHBTC\n",
    "- MACD > 0 แสดงว่าราคากำลังขึ้น หรือก็คือมีแนวโน้มว่าในอนาคต BTC จะมีราคาสูงขึ้น\n",
    "    - ถ้าเราถือ ETH เราควรถือไว้ รอขายในอนาคต\n",
    "    - ถ้าเราถือ BTC เราควรขายเพื่อซื้อ ETH\n",
    "- MACD < 0 แสดงว่าราคากำลังลง หรือก็คือมีแนวโน้มว่าในอนาคต BTC จะมีราคาต่ำขึ้น\n",
    "    - ถ้าเราถือ ETH เราควรขายเพื่อซื้อ BTC\n",
    "    - ถ้าเราถือ BTC เราควรถือไว้ รอขายในอนาคต\n",
    "\n",
    "** ยิ่งค่าห่างจาก 0 ยิ่งมีแนวโน้มที่จะไปทางนั้นๆ สูง\n",
    "\n",
    "- จังหวะที่ควรซื้อ หรือขาย คือจังหวะที่เส้นของ MACD ตัดกับเส้น MACD_Signal\n",
    "    - MACD ตัดแล้วขึ้นสูงกว่า MACD_Signal: เป็นช่วงราคากำลังขึ้น\n",
    "    - MACD ตัดแล้วต่ำกว่า MACD_Signal: เป็นช่วงราคากำลังลง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5832f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_macd(df, fast=12, slow=26, signal=9):\n",
    "    # Calculate EMA fast and slow\n",
    "    df['ema_fast'] = df['close'].ewm(span=fast, adjust=False).mean()\n",
    "    df['ema_slow'] = df['close'].ewm(span=slow, adjust=False).mean()\n",
    "    \n",
    "    # MACD line\n",
    "    df['macd'] = df['ema_fast'] - df['ema_slow']\n",
    "    \n",
    "    # Signal line\n",
    "    df['macd_signal'] = df['macd'].ewm(span=signal, adjust=False).mean()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce99a58",
   "metadata": {},
   "source": [
    "## 3.4. Bollinger Bands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c45401",
   "metadata": {},
   "source": [
    "- ประกอบด้วย 3 เส้นหลัก:\n",
    "\n",
    "1. เส้นกลาง (Middle Band) : SMA ของ close หมายถึงแนวโน้มราคากลาง ๆ ในช่วงเวลาที่กำหนด\n",
    "\n",
    "2. เส้นบน (Upper Band): SMA + 2SD บ่งบอกขอบเขตราคาที่ \"สูงกว่าปกติ\" หรือเป็นระดับแนวต้าน\n",
    "\n",
    "3. เส้นล่าง (Lower Band): SMA - 2SD บ่งบอกขอบเขตราคาที่ \"ต่ำกว่าปกติ\" หรือเป็นระดับแนวรับ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516ee52",
   "metadata": {},
   "source": [
    "พิจารณา ETHBTC\n",
    "- มี 4 Case ที่เกิดขึ้นได้\n",
    "    1. Close Price ชิด Upper Band: ราคาสูงเกินไปแล้ว อาจมีโอกาสราคาตกลงในเร็ว ๆ นี้\n",
    "        - ถ้าเราถือ ETH ควรขายเพื่อซื้อ BTC\n",
    "        - ถ้าเราถือ BTC ควรถือไว้ รอขายในอนาคต\n",
    "    2. Close Price ชิด Lower Band: ราคาต่ำเกินไปแล้ว อาจมีโอกาสราคาขึ้นในเร็ว ๆ นี้\n",
    "        - ถ้าเราถือ ETH ควรถือไว้ รอขายในอนาคต\n",
    "        - ถ้าเราถือ BTC ควรขายเพื่อซื้อ ETH\n",
    "    3. Upper Band กับ Lower Band เข้ามาชิดกัน: ความผันผวนต่ำ เตรียมเคลื่อนไหว\n",
    "        - ถ้า Close Price สูงกว่า Upper Band อาจเป็นสัญญาณซื้อ ETH ขาย BTC\n",
    "        - ถ้า Close Price ต่ำกว่า Lower Band อาจเป็นสัญญาณขาย ETH ซื้อ BTC\n",
    "    4. Upper Band กับ Lower Band ห่างออกจากกัน: ความผันผวนสูง\n",
    "        - ถ้า Close Price สูงขึ้น และอยู่ใกล้ Upper Band ควรถือ ETH ต่อเนื่อง หรือซื้อเพิ่ม\n",
    "        - ถ้า Close Price ลดลง และอยู่ใกล้ Lower Band → ควรขาย ETH ซื้อ BTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566235de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bollinger(df, period=20, std_dev=2):\n",
    "    df['bb_middle'] = df['close'].rolling(window=period).mean()\n",
    "    df['bb_std'] = df['close'].rolling(window=period).std()\n",
    "    \n",
    "    df['bb_upper'] = df['bb_middle'] + std_dev * df['bb_std']\n",
    "    df['bb_lower'] = df['bb_middle'] - std_dev * df['bb_std']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903a9c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_all_indicators(df) :\n",
    "    df = add_moving_average(df)\n",
    "    df = add_rsi(df)\n",
    "    df = add_macd(df)\n",
    "    df = add_bollinger(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fef472f",
   "metadata": {},
   "source": [
    "# 4. Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29c1c3d",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9529ccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_train_df = add_all_indicators(train_df)\n",
    "ind_train_df.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "ind_test_df = add_all_indicators(test_df)\n",
    "ind_test_df.set_index(\"timestamp\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea907810",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ca0185",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8f7a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c24be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d284a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bb_middle\\n\", ind_train_df[\"bb_middle\"])\n",
    "print(\"bb_std\\n\", ind_train_df[\"bb_std\"])\n",
    "print(\"bb_upper\\n\", ind_train_df[\"bb_upper\"])\n",
    "print(\"bb_lower\\n\", ind_train_df[\"bb_lower\"])\n",
    "print(\"rsi\\n\", ind_train_df[\"rsi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3102266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_train_df.dropna(subset=['bb_lower', 'bb_upper', 'bb_middle', 'bb_std', 'rsi'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80e0e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_train_df['price_direction'] = (ind_train_df['close'].shift(-1) > ind_train_df['close']).astype(int)\n",
    "ind_train_df['price_direction'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8902798",
   "metadata": {},
   "source": [
    "- 0 คือ ราคาปิดในอนาคต ***น้อยกว่า*** ราคาปิดปัจจุบัน -> ในตอนนี้ควรขาย\n",
    "- 1 คือ ราคาปิดในอนาคต ***มากกว่า*** ราคาปิดปัจจุบัน -> ในตอนนี้ควรซื้อ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d660850",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f1667",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d555f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bb_middle\\n\", ind_test_df[\"bb_middle\"])\n",
    "print(\"bb_std\\n\", ind_test_df[\"bb_std\"])\n",
    "print(\"bb_upper\\n\", ind_test_df[\"bb_upper\"])\n",
    "print(\"bb_lower\\n\", ind_test_df[\"bb_lower\"])\n",
    "print(\"rsi\\n\", ind_test_df[\"rsi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a64a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_test_df.dropna(subset=['bb_lower', 'bb_upper', 'bb_middle', 'bb_std', 'rsi'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1d2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955944a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_test_df['price_direction'] = (ind_test_df['close'].shift(-1) > ind_test_df['close']).astype(int)\n",
    "ind_test_df['price_direction'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48403ec",
   "metadata": {},
   "source": [
    "## Preparing to Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17fc45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c5236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_train_df['price_direction'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746b9f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 2025\n",
    "test_size = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02876a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "features = [\n",
    "    'SMA_20', 'SMA_50', 'SMA_200',\n",
    "    'EMA_12', 'EMA_26',\n",
    "    'rsi', \n",
    "    'macd', 'macd_signal',\n",
    "    'bb_upper', 'bb_middle', 'bb_lower',\n",
    "    'trend_strength', 'price_sma20_dist', 'price_sma50_dist',\n",
    "    'price_sma200_dist',\n",
    "    'price_ema12_dist', 'price_ema26_dist', 'bullish_alignment'\n",
    "]\n",
    "\n",
    "target = 'price_direction'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be587dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    # print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    # print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    # print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    precision_all = precision_score(y_test, y_pred, average=None)\n",
    "    precision_class0 = precision_all[0]\n",
    "    precision_class1 = precision_all[1]\n",
    "\n",
    "    recall_all = recall_score(y_test, y_pred, average=None)\n",
    "    recall_class0 = recall_all[0]\n",
    "    recall_class1 = recall_all[1]\n",
    "\n",
    "    f1_all = f1_score(y_test, y_pred, average=None)\n",
    "    f1_class0 = f1_all[0]\n",
    "    f1_class1 = f1_all[1]\n",
    "\n",
    "    try:\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_score = model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            y_score = model.decision_function(X_test)\n",
    "        roc_auc = roc_auc_score(y_test, y_score)\n",
    "    except Exception as e:\n",
    "        roc_auc = None\n",
    "        \n",
    "    # print(f\"ROC-AUC: {roc_auc:.3f}\" if roc_auc is not None else \"ROC-AUC: N/A\")\n",
    "\n",
    "    # print(f\"Precision (class 0): {precision_class0:.3f}, (class 1): {precision_class1:.3f}\")\n",
    "    # print(f\"Recall (class 0): {recall_class0:.3f}, (class 1): {recall_class1:.3f}\")\n",
    "    # print(f\"F1-score (class 0): {f1_class0:.3f}, (class 1): {f1_class1:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision_class0\": precision_class0,\n",
    "        \"precision_class1\": precision_class1,  \n",
    "        \"recall_class0\": recall_class0,\n",
    "        \"recall_class1\": recall_class1,\n",
    "        \"f1_class0\": f1_class0,\n",
    "        \"f1_class1\": f1_class1,\n",
    "        \"roc_auc\": roc_auc\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3124cf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model_results(lr_evaluation, rf_evaluation, xgb_evaluation, knn_evaluation, svm_evaluation): \n",
    "    data = {\n",
    "        \"model\": [\"LR\", \"RF\", \"XGB\", \"KNN\", \"SVM\"],\n",
    "        \"accuracy\": [lr_evaluation[\"accuracy\"], rf_evaluation[\"accuracy\"], \n",
    "                    xgb_evaluation[\"accuracy\"], knn_evaluation[\"accuracy\"], \n",
    "                    svm_evaluation[\"accuracy\"]],\n",
    "        \"precision_class0\": [lr_evaluation[\"precision_class0\"], rf_evaluation[\"precision_class0\"],\n",
    "                            xgb_evaluation[\"precision_class0\"], knn_evaluation[\"precision_class0\"], \n",
    "                            svm_evaluation[\"precision_class0\"]],\n",
    "        \"precision_class1\": [lr_evaluation[\"precision_class1\"], rf_evaluation[\"precision_class1\"],\n",
    "                            xgb_evaluation[\"precision_class1\"], knn_evaluation[\"precision_class1\"],\n",
    "                            svm_evaluation[\"precision_class1\"]],\n",
    "        \"recall_class0\": [lr_evaluation[\"recall_class0\"], rf_evaluation[\"recall_class0\"],\n",
    "                            xgb_evaluation[\"recall_class0\"], knn_evaluation[\"recall_class0\"],\n",
    "                            svm_evaluation[\"recall_class0\"]],\n",
    "        \"recall_class1\": [lr_evaluation[\"recall_class1\"], rf_evaluation[\"recall_class1\"],\n",
    "                            xgb_evaluation[\"recall_class1\"], knn_evaluation[\"recall_class1\"],\n",
    "                            svm_evaluation[\"recall_class1\"]],\n",
    "        \"f1_class0\": [lr_evaluation[\"f1_class0\"], rf_evaluation[\"f1_class0\"],\n",
    "                        xgb_evaluation[\"f1_class0\"], knn_evaluation[\"f1_class0\"],\n",
    "                        svm_evaluation[\"f1_class0\"]],\n",
    "        \"f1_class1\": [lr_evaluation[\"f1_class1\"], rf_evaluation[\"f1_class1\"],\n",
    "                        xgb_evaluation[\"f1_class1\"], knn_evaluation[\"f1_class1\"],\n",
    "                        svm_evaluation[\"f1_class1\"]],\n",
    "        \"roc_auc\": [lr_evaluation[\"roc_auc\"], rf_evaluation[\"roc_auc\"],\n",
    "                    xgb_evaluation[\"roc_auc\"], knn_evaluation[\"roc_auc\"],\n",
    "                    svm_evaluation[\"roc_auc\"]]\n",
    "    }\n",
    "    \n",
    "    results_df = pd.DataFrame(data)\n",
    "    results_df.set_index(\"model\", inplace=True)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539b9333",
   "metadata": {},
   "source": [
    "## Model Training V1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4224ffd",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01679741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_model_v1(df):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    # 1. Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 2. Train/Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                        test_size=test_size, shuffle=False, \n",
    "                                                        random_state=random_state)\n",
    "    model = LogisticRegression(random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 3. Scoring\n",
    "    lr_evaluation = model_evaluation(model, X_train, X_test, y_train, y_test)\n",
    "    return lr_evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7376c2f7",
   "metadata": {},
   "source": [
    "### Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0f9ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_model_v1(df):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    # 1. Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 2. Train/Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                        test_size=test_size, shuffle=False, \n",
    "                                                        random_state=random_state)\n",
    "    model = RandomForestClassifier(random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 3. Scoring\n",
    "    rf_evaluation = model_evaluation(model, X_train, X_test, y_train, y_test)\n",
    "    return rf_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec22b04",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab919f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_model_v1(df):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    # 1. Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 2. Train/Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                        test_size=test_size, shuffle=False, \n",
    "                                                        random_state=random_state)\n",
    "    model = XGBClassifier(random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 3. Scoring\n",
    "    xgb_evaluation = model_evaluation(model, X_train, X_test, y_train, y_test)\n",
    "    return xgb_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ea426b",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1093c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model_v1(df):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    # 1. Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 2. Train/Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                        test_size=test_size, shuffle=False, \n",
    "                                                        random_state=random_state)\n",
    "    model = KNeighborsClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 3. Scoring\n",
    "    knn_evaluation = model_evaluation(model, X_train, X_test, y_train, y_test)\n",
    "    return knn_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c918593",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad38b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_model_v1(df):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    # 1. Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 2. Train/Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size, \n",
    "                                                        shuffle=False, random_state=random_state)\n",
    "    model = SVC(random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 3. Scoring\n",
    "    svm_evaluation = model_evaluation(model, X_train, X_test, y_train, y_test)\n",
    "    return svm_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c9a08f",
   "metadata": {},
   "source": [
    "## Model Summary V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad72fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_evaluation = lr_model_v1(ind_train_df)\n",
    "rf_evaluation = rf_model_v1(ind_train_df)\n",
    "xgb_evaluation = xgb_model_v1(ind_train_df)\n",
    "knn_evaluation = knn_model_v1(ind_train_df)\n",
    "svm_evaluation = svm_model_v1(ind_train_df)\n",
    "\n",
    "results_df_v1 = show_model_results(lr_evaluation, rf_evaluation, xgb_evaluation, \n",
    "                                   knn_evaluation, svm_evaluation)\n",
    "\n",
    "results_df_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da29465d",
   "metadata": {},
   "source": [
    "## Model Training V2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab675a8",
   "metadata": {},
   "source": [
    "- เพิ่ม Hyperparameter Tuning \n",
    "- เพิ่ม SMOTE เพราะ Class 0 และ Class 1 มีสัดส่วนต่างกันเกินไป"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f434b64",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005f4aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_model_v2(df):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    # 1. Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 2. Train/Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=test_size, shuffle=False, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # 3. Balance Data\n",
    "    sm = SMOTE(random_state=random_state)\n",
    "    X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    # 4. Hyperparameter Tuning\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'solver': ['lbfgs', 'liblinear'],\n",
    "        'class_weight': ['balanced']\n",
    "    }\n",
    "    grid = GridSearchCV(\n",
    "        LogisticRegression(max_iter=1000, random_state=random_state), \n",
    "        param_grid, scoring='accuracy'\n",
    "    )\n",
    "    grid.fit(X_train_res, y_train_res)\n",
    "    # print(\"Best Params:\", grid.best_params_)\n",
    "    # print(\"Best CV Score:\", grid.best_score_)\n",
    "\n",
    "    # 5. Train model\n",
    "    model = LogisticRegression(max_iter=1000, **grid.best_params_, random_state=random_state)\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "\n",
    "    # 6. Scoring\n",
    "    lr_evaluation = model_evaluation(model, X_train_res, X_test, y_train_res, y_test)\n",
    "    return lr_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be01378",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469bd264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_model_v2(df):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    # 1. Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 2. Train/Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=test_size, shuffle=False, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # 3. Balance Data\n",
    "    sm = SMOTE(random_state=random_state)\n",
    "    X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    # 4. Hyperparameter Tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [4, 8, 16, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'class_weight': ['balanced']\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(RandomForestClassifier(random_state=random_state), param_grid,\n",
    "                        scoring='accuracy')\n",
    "    grid.fit(X_train_res, y_train_res)\n",
    "    # print(\"Best Params:\", grid.best_params_)\n",
    "    # print(\"Best CV Score:\", grid.best_score_)\n",
    "\n",
    "    # 5. Train model\n",
    "    model = RandomForestClassifier(random_state=random_state, **grid.best_params_)\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "\n",
    "    # 6. Scoring\n",
    "    rf_evaluation = model_evaluation(model, X_train_res, X_test, y_train_res, y_test)\n",
    "    return rf_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92efc840",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ed6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_model_v2(df):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    # 1. Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 2. Train/Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=test_size, shuffle=False, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # 3. Balance Data\n",
    "    sm = SMOTE(random_state=random_state)\n",
    "    X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    # 4. Hyperparameter Tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 6, 10],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 1.0],\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=random_state),\n",
    "        param_grid, scoring='accuracy'\n",
    "    )\n",
    "    grid.fit(X_train_res, y_train_res)\n",
    "    # print(\"Best Params:\", grid.best_params_)\n",
    "    # print(\"Best CV Score:\", grid.best_score_)\n",
    "\n",
    "    # 5. Train model\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss',\n",
    "                        random_state=random_state, **grid.best_params_)\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "\n",
    "    # 6. Scoring\n",
    "    xgb_evaluation = model_evaluation(model, X_train_res, X_test, y_train_res, y_test)\n",
    "    return xgb_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10684d33",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebefe2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model_v2(df):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    # 1. Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 2. Train/Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=test_size, shuffle=False, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # 3. Balance Data (SMOTE เฉพาะ train)\n",
    "    sm = SMOTE(random_state=random_state)\n",
    "    X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    # 4. Hyperparameter Tuning\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan'],\n",
    "    }\n",
    "    grid = GridSearchCV(KNeighborsClassifier(), param_grid, scoring='accuracy')\n",
    "    grid.fit(X_train_res, y_train_res)\n",
    "    # print(\"Best Params:\", grid.best_params_)\n",
    "    # print(\"Best CV Score:\", grid.best_score_)\n",
    "\n",
    "    # 5. Train model\n",
    "    model = KNeighborsClassifier(**grid.best_params_)\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "\n",
    "    # 6. Scoring\n",
    "    knn_evaluation = model_evaluation(model, X_train_res, X_test, y_train_res, y_test)\n",
    "    return knn_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afb6f1b",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ec43c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_model_v2(df):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    # 1. Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 2. Train/Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=test_size, shuffle=False, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # 3. Balance Data\n",
    "    sm = SMOTE(random_state=random_state)\n",
    "    X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    # 4. Hyperparameter Tuning\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'class_weight': ['balanced']\n",
    "    }\n",
    "    grid = GridSearchCV(SVC(), param_grid, scoring='accuracy')\n",
    "    grid.fit(X_train_res, y_train_res)\n",
    "    # print(\"Best Params:\", grid.best_params_)\n",
    "    # print(\"Best CV Score:\", grid.best_score_)\n",
    "\n",
    "    # 5. Train model\n",
    "    model = SVC(**grid.best_params_, random_state=random_state)\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "\n",
    "    # 6. Scoring\n",
    "    svm_evaluation = model_evaluation(model, X_train_res, X_test, y_train_res, y_test)\n",
    "    return svm_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009b558c",
   "metadata": {},
   "source": [
    "## Model Result V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05550555",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_evaluation_v2 = lr_model_v2(ind_train_df)\n",
    "rf_evaluation_v2 = rf_model_v2(ind_train_df)\n",
    "xgb_evaluation_v2 = xgb_model_v2(ind_train_df)\n",
    "knn_evaluation_v2 = knn_model_v2(ind_train_df)\n",
    "svm_evaluation_v2 = svm_model_v2(ind_train_df)\n",
    "\n",
    "results_df_v2 = show_model_results(lr_evaluation_v2, rf_evaluation_v2, xgb_evaluation_v2, \n",
    "                                   knn_evaluation_v2, svm_evaluation_v2)\n",
    "\n",
    "results_df_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8815978f",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc461e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy', 'precision_class0', 'precision_class1', 'recall_class0', \n",
    "           'recall_class1', 'f1_class0', 'f1_class1', 'roc_auc']\n",
    "\n",
    "models = results_df_v1.index.tolist()\n",
    "x = np.arange(len(models))\n",
    "width = 0.3\n",
    "\n",
    "fig, axes = plt.subplots(len(metrics), 1, figsize=(12, 4 * len(metrics)), sharey=True)\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    axes[i].bar(x - width/2, results_df_v1[metric], width, label='V1')\n",
    "    axes[i].bar(x + width/2, results_df_v2[metric], width, label='V2')\n",
    "    axes[i].set_title(metric)\n",
    "    axes[i].set_xticks(x)\n",
    "    axes[i].set_xticklabels(models, rotation=20)\n",
    "    axes[i].legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5b7234",
   "metadata": {},
   "source": [
    "# 5. Picking Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd17177",
   "metadata": {},
   "source": [
    "ทดสอบกับ 20 เหรียญ แล้วหา Model ที่ดีที่สุด"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff73dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = list(api.get_n_symbol(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a62ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_ind_df(symbol):\n",
    "    api = BinanceAPI(api_key, api_secret)\n",
    "    train_df = collect_historical_data(api, symbol, interval=\"5m\", days=4)\n",
    "    test_df = collect_historical_data(api, symbol, interval=\"5m\", days=1, end_time=None)\n",
    "    test_df = test_df[test_df['timestamp'] > train_df['timestamp'].max()]\n",
    "    \n",
    "    ind_train_df = add_all_indicators(train_df)\n",
    "    ind_train_df.set_index(\"timestamp\", inplace=True)\n",
    "    ind_train_df.dropna(subset=['bb_lower', 'bb_upper', 'bb_middle', 'bb_std', 'rsi'], inplace=True)\n",
    "    ind_train_df['price_direction'] = (ind_train_df['close'].shift(-1) > ind_train_df['close']).astype(int)\n",
    "    \n",
    "    ind_test_df = add_all_indicators(test_df)\n",
    "    ind_test_df.set_index(\"timestamp\", inplace=True)\n",
    "    ind_test_df.dropna(subset=['bb_lower', 'bb_upper', 'bb_middle', 'bb_std', 'rsi'], inplace=True)\n",
    "    ind_test_df['price_direction'] = (ind_test_df['close'].shift(-1) > ind_test_df['close']).astype(int)\n",
    "    \n",
    "    return ind_train_df, ind_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a015ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1, test_df1 = create_train_test_ind_df(symbols[0])\n",
    "train_df2, test_df2 = create_train_test_ind_df(symbols[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1390f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68726bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
